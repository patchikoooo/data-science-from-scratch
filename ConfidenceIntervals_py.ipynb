{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ConfidenceIntervals.py",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/patchikoooo/data-science-from-scratch/blob/master/ConfidenceIntervals_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gz1DRy_KjlqB",
        "colab_type": "text"
      },
      "source": [
        "# **Confidence Intervals**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0zQTdGqjkmu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N566knD32NiG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normal_cdf(x, mu=0, sigma=1):\n",
        "    return (1 + math.erf((x-mu) / math.sqrt(2) / sigma)) / 2\n",
        "\n",
        "def inverse_normal_cdf(p, mu=0, sigma=1, tolerance=0.00001):\n",
        "    # find approximate inverse using binary search\n",
        "    \n",
        "    # if not standard, compute standard and rescale\n",
        "    if mu != 0 or sigma != 1:\n",
        "        return mu + sigma * inverse_normal_cdf(p, tolerance=tolerance)\n",
        "    \n",
        "    low_z, low_p = -10.0, 0          # normalcdf(-10) is (very close to) 0\n",
        "    hi_z, hi_p = 10.0, 1             # normal_cdf(10) is (very close to) 1\n",
        "    while hi_z - low_z > tolerance:\n",
        "        mid_z = (low_z + hi_z) / 2   # consider the midpoint\n",
        "        mid_p = normal_cdf(mid_z)    # and the cdf's value there\n",
        "        if mid_p < p:\n",
        "            # midpoint is still too low, search above it\n",
        "            low_z, low_p = mid_z, mid_p\n",
        "        elif mid_p > p:\n",
        "            # midpoint is still too high, search below it\n",
        "            hi_z, hi_p = mid_z, mid_p\n",
        "        else:\n",
        "            break\n",
        "    \n",
        "    return mid_z\n",
        "\n",
        "normal_probability_below = normal_cdf\n",
        "\n",
        "def normal_approximation_to_binomial(n, p):\n",
        "    # finds mu and sigma corresponding to Binomial(n, p)\n",
        "    mu = p*n\n",
        "    sigma = math.sqrt(n*p*(1-p))\n",
        "    return mu, sigma"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdMpV0yg2PER",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we can use normal_cdf to figure out that probability that its realized value\n",
        "#    lies within (or outside) a particular interval\n",
        "\n",
        "# the normal cdf is the probability the variable is below a threshold\n",
        "normal_probability_below = normal_cdf\n",
        "\n",
        "# it's above the threshold if it's not below the threshold\n",
        "def normal_probability_above(lo, mu=0, sigma=1):\n",
        "    return 1 - normal_cdf(lo, mu, sigma)\n",
        "\n",
        "# it's between if it's less than hi, but not less than lo\n",
        "def normal_probability_between(lo, hi, mu=0, sigma=1):\n",
        "    return normal_cdf(hi, mu, sigma) - normal_cdf(lo, mu, sigma)\n",
        "\n",
        "# it's outside if it's not between\n",
        "def normal_probability_outside(lo, hi, mu=0, sigma=1):\n",
        "    return 1 - normal_probability_between(lo, hi, mu=0, sigma=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8zMmOkv2Tfa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We can also do reverse -- find either the nontail region or the (symmetric) interval\n",
        "#   around the mean that accounts for a certain level of likelihood.\n",
        "\n",
        "# For example, if we want to find an interval centered at the mean and containing\n",
        "    # 60% probability, then we find the cutoffs where the upper and lower tails\n",
        "    # each contain 20% of the probability( leaving 60%)\n",
        "\n",
        "\n",
        "# z --> z score\n",
        "def normal_upper_bound(probability, mu=0, sigma=1):\n",
        "    \"\"\"returns the z for which P(Z <= z) = probability\"\"\"\n",
        "    return inverse_normal_cdf(probability, mu, sigma)\n",
        "\n",
        "def normal_lower_bound(probability, mu=0, sigma=1):\n",
        "    \"\"\"returns the z for which P(Z >= z)\"\"\"\n",
        "    return inverse_normal_cdf(1 - probability, mu, sigma)\n",
        "\n",
        "def normal_two_sided_bounds(probability, mu=0, sigma=1):\n",
        "    \"\"\"returns the symmetric (about the mean) bounds that contain\n",
        "        the specified probability\"\"\"\n",
        "    tail_probability = (1 - probability) / 2\n",
        "\n",
        "    # upper bound should have tail_probability above it\n",
        "    upper_bound = normal_lower_bound(tail_probability, mu, sigma)\n",
        "\n",
        "    # lower bound should have tail probability below it\n",
        "    lower_bound = normal_upper_bound(tail_probability, mu, sigma)\n",
        "\n",
        "    return lower_bound, upper_bound\n",
        "\n",
        "def two_sided_p_value(x, mu=0, sigma=1):\n",
        "    if x >= mu:\n",
        "        # if x is greater than the mean, the tail is what's greater than x\n",
        "        return 2 * normal_probability_above(x, mu, sigma)\n",
        "    else:\n",
        "        # if x is less thatn the mean, the tail is what's less than x\n",
        "        return 2 * normal_probability_below(x, mu, sigma)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrR8SOifkjlP",
        "colab_type": "code",
        "outputId": "69cc78e2-4f0e-4b98-ae23-f33a016110a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "\"\"\" For example, we can estimate the probability of the unfair coin by looking\n",
        "        at the average value of the Bernoulli variables corresponding to each flip.\n",
        "        If we observe 525 heads out of 1,000 flips, then we can estimate the\n",
        "        observed value of the parameter.\n",
        "    \n",
        "    How confident can we be about this estimate? Weell, if we knew the exact\n",
        "        value of p, CLT tells us that the average of those Bernoulli variables\n",
        "        should be approximately normal, with mean p and standard deviation \"\"\"\n",
        "\n",
        "math.sqrt(p * (1-p) / 1000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-907dc7bebf46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         should be approximately normal, with mean p and standard deviation \"\"\"\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'p' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zbs0l1sulJXN",
        "colab_type": "code",
        "outputId": "056ccada-bf65-4be2-9a48-1936f79c10e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# since we don't know our p, we use p_hat\n",
        "p_hat = 525 / 1000\n",
        "mu = p_hat\n",
        "sigma = math.sqrt(p_hat * (1 - p_hat) / 1000)\n",
        "print(\"(mu, sigma)\", (mu, sigma))\n",
        "\n",
        "# This is not entirely justified, but people seem to do it anyway.\n",
        "#   Using the normal approximation, we conclude that we are \"95% confident\"\n",
        "#   that the folloowing interval contains the true parameter p.\n",
        "\n",
        "normal_two_sided_bounds(0.95, mu, sigma)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(mu, sigma) (0.525, 0.015791611697353755)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.4940490278129096, 0.5559509721870904)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNiCNr_gllbE",
        "colab_type": "code",
        "outputId": "bb771226-0e48-4af8-99f8-c94fd738dc29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# trying 540 heads out of 1000, we'd have:\n",
        "\n",
        "p_hat = 540 / 1000\n",
        "mu = p_hat\n",
        "sigma = math.sqrt(p_hat * (1 - p_hat) / 1000)\n",
        "print(\"(mu, sigma)\", (mu, sigma))\n",
        "normal_two_sided_bounds(0.95, mu, sigma)\n",
        "\n",
        "# Here, \"fair coin\" doesn't lie in the confidence interval"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(mu, sigma) (0.54, 0.015760710643876435)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5091095927295919, 0.5708904072704082)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKoY0j103jc5",
        "colab_type": "text"
      },
      "source": [
        "# **P-hacking**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfe_8S693i2B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" A procedure that erroneously rejects the null hypothesis only 5% of the time\n",
        "        - by definition - 5% of the time erroneously reject the hypothesis \"\"\"\n",
        "\n",
        "def run_experiment():\n",
        "    \"\"\" flip a fair coin 1000 times, True = heads, False = tails \"\"\"\n",
        "    return [random.random() < 0.5 for _ in range(1000)]\n",
        "\n",
        "def reject_fairness(experiment):\n",
        "    \"\"\" using the 5% significance levels \"\"\"\n",
        "    num_heads = len([flip for flip in experiment if flip])\n",
        "    return num_heads < 469 or num_heads > 531"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13qmMKLs3H7b",
        "colab_type": "code",
        "outputId": "0148f6c2-710c-46df-deb0-4af2a4b89835",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "random.seed(0)\n",
        "experiments = [run_experiment() for _ in range(1000)]\n",
        "num_rejections = len([experiment for experiment in experiments\n",
        "                      if reject_fairness(experiment)])\n",
        "num_rejections"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYLvZljI6jge",
        "colab_type": "code",
        "outputId": "fcc169b2-9a8c-4bec-cdec-c235367e4f17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\"\"\" Running AB Test \"\"\"\n",
        "\n",
        "\"\"\" One of your primary responsibilities at DataSciencester is experience optimization,\n",
        "which is a euphemism for trying to get people to click on advertisements.\n",
        "\n",
        "One of your advertisers has developed a new energy drink targeted at data scientists,\n",
        "    and the VP of Advertisements wants your help choosing between advertisement A\n",
        "    (“tastes great!”) and advertisement B (“less bias!”). Being a scientist,\n",
        "    you decide to run an experiment by randomly showing site visitors one\n",
        "    of the two advertisements and tracking how many people click on each one.\n",
        "    \n",
        "    If 990 out of 1,000 A-viewers click their ad while only 10 out of 1,000\n",
        "    B-viewers click their ad, you can be pretty confident that A is the better\n",
        "    ad. But what if the differences are not so stark? Here’s where you’d use\n",
        "    statistical inference. \"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' One of your primary responsibilities at DataSciencester is experience optimization,\\nwhich is a euphemism for trying to get people to click on advertisements.\\n\\nOne of your advertisers has developed a new energy drink targeted at data scientists,\\n    and the VP of Advertisements wants your help choosing between advertisement A\\n    (“tastes great!”) and advertisement B (“less bias!”). Being a scientist,\\n    you decide to run an experiment by randomly showing site visitors one\\n    of the two advertisements and tracking how many people click on each one.\\n    \\n    If 990 out of 1,000 A-viewers click their ad while only 10 out of 1,000\\n    B-viewers click their ad, you can be pretty confident that A is the better\\n    ad. But what if the differences are not so stark? Here’s where you’d use\\n    statistical inference. '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxpvRYVdiLF3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def estimated_parameters(N, n):\n",
        "    # n is the number of successes and N is the total number of trials\n",
        "    p = n / N\n",
        "    sigma = math.sqrt(p * (1 - p) / N)\n",
        "    return p, sigma"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRPQhaGTiaMr",
        "colab_type": "code",
        "outputId": "325cdb20-5bc9-4549-d758-490f3562c578",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "estimated_parameters(1000, 800)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8, 0.012649110640673518)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsYlAonWifST",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" If we assume those two normals are independent, then their difference should\n",
        "        also be normal with mean Pb - Pa and standard deviation\n",
        "        math.sqrt(sigmaA^2 + sigmaB^2)\n",
        "\n",
        "    Note that this is sort of CHEATING. The math only works out exactly like this\n",
        "        if you know the standard deviations. Here we're estimating them from the data,\n",
        "        which means that we really should be using a t-distribution. But for large\n",
        "        enough data sets, it's close enought that it doesn't make much of a\n",
        "        difference.\n",
        "\n",
        "    This means we can test the null hypothesis that Pa and Pb are the same.\n",
        "        that is, that Pa - Pb == 0;\n",
        "        using the statistic: \"\"\"\n",
        "\n",
        "def a_b_test_statistic(N_A, n_A, N_B, n_B):\n",
        "    p_A, sigma_A = estimated_parameters(N_A, n_A)\n",
        "    p_B, sigma_B = estimated_parameters(N_B, n_B)\n",
        "    # mean difference and sigma difference\n",
        "    # sigma difference will also be sum since squaring sigma will yield\n",
        "    #       positive number\n",
        "    return (p_B - p_A) / math.sqrt(sigma_A ** 2 + sigma_B ** 2)\n",
        "\n",
        "    # this should be approximately be a standard normal."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpSdaK4Qmadn",
        "colab_type": "code",
        "outputId": "e13f6bf2-758f-454a-b87c-ba11771911a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\" For example, if \"tastes great\" gets 200 clicks our of 1000 views and \"less\n",
        "        bias\" gets 180 clicks out of 1000 views, the statistic equals: \"\"\"\n",
        "\n",
        "z = a_b_test_statistic(1000, 200, 1000, 180)\n",
        "print(z)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-1.1403464899034472\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PUUJyPSm2Od",
        "colab_type": "code",
        "outputId": "6d38363b-912b-4bba-aa91-8461f81e1ada",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\" The probability of seeing such a large difference if the means \n",
        "        were actually equal would be: \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "# Which is large enough that you can't conclude there's much of a difference.\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.254141976542236\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym-C5LCUnTX-",
        "colab_type": "code",
        "outputId": "3e81d08b-1d9d-496d-c18f-c77dcc330866",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# On the other hand, if \"less bias\" only got 150 chicks, we'd have:\n",
        "z = a_b_test_statistic(1000, 200, 1000, 150)\n",
        "print(two_sided_p_value(z))\n",
        "\n",
        "#   which means there's only a 0.003 probability you'd see such a large\n",
        "#   if the ads were equally effective."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.003189699706216853\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWv1_LnGoZGO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjqGL2LmoqjG",
        "colab_type": "text"
      },
      "source": [
        "# **Bayesian Inference**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YA41F3HzovEG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "The procedures we've looked at have involved making probability statements about\n",
        "    our tests: \"there's only a 3% chance you'd observe such an extreme statistic\n",
        "    if our null hypothesis were true.\n",
        "\"\"\"\n",
        "\n",
        "\"\"\" An  alternative approach to inference involves treating the unknown parameters\n",
        "        themselves as random variables. The analyst ( that's you ) starts with a\n",
        "        prior distribution for the parameters and then uses the observed data\n",
        "        and Baye's Theorem to get an updated posterioir distribution for the\n",
        "        parameters. Rather than making probability judgments about the tests,\n",
        "        you make probability judgments about the parameters themselves. \"\"\"\n",
        "\n",
        "# For example, when unknown parameter is a probability, we often use a prior\n",
        "#   from the Beta distribution, which puts all its probability between 0 and 1:\n",
        "\n",
        "def B(alpha, beta):\n",
        "    # normalizing constant so that the total probability is 1\n",
        "    return math.gamma(alpha) * math.gamma(beta) / math.gamma(alpha + beta)\n",
        "\n",
        "def beta_pdf(x, alpha, beta):\n",
        "    if x < 0 or x > 1:   # no weight outside of [0, 1]\n",
        "        return 0\n",
        "    return x ** (alpha - 1) * (1 - x) ** (betta - 1) / B(alpha, beta)\n",
        "\n",
        "# this distribution centers its weight at:\n",
        "#       alpha / (alpha + beta)\n",
        "#       and the larger alpha and beta are, the \"tighter\" the distribution is\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqO9Qt1erXUL",
        "colab_type": "code",
        "outputId": "bd98919d-6fbb-4195-b69d-ac22907cadab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\"\"\"\n",
        "For example, if alpha and beta are both 1, it's just the uniform distribtion\n",
        "    (centered at 0.5, very dispered). If alpha is much larger than beta,\n",
        "    most of the weights is near 1. And if alpha is much smaller than beta,\n",
        "    most of the weight is near zero.\n",
        "\"\"\"\n",
        "\n",
        "\"\"\" Let's assume a priod distribution on p. Maybe we don't want to take\n",
        "        a stand on whether the coin if fair, and we choose alpha and beta\n",
        "        to both equal 1. Or maybe we have a strong belief that it lands heads\n",
        "        55% of the time, and we choose alpha equals 55, beta equals 45.\n",
        "\n",
        "        Then we flip our coin a bunch of times and see h heads and t tails.\n",
        "        Baye's Theorem ( and some mathematics that's too tedious for us to go\n",
        "        through here) tells us that the posterioir distribution for p is again\n",
        "        a Beta distribution with parameters alpha + h and beta + t. \"\"\"\n",
        "\n",
        "\"\"\" NOTE:\n",
        "It is coincidence that the posterior distribution was again a Beta distribution.\n",
        "    The number of heads given by a Binomial distribution, and the Beta is the \n",
        "    conjugate prioir to the binomial distribution. This means that whenever you\n",
        "    update a Beta prior using observations from the corresponding binomial, you\n",
        "    will get back a Beta posterior.\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' NOTE:\\nIt is coincidence that the posterior distribution was again a Beta distribution.\\n    The number of heads given by a Binomial distribution, and the Beta is the \\n    conjugate prioir to the binomial distribution. This means that whenever you\\n    update a Beta prior using observations from the corresponding binomial, you\\n    will get back a Beta posterior.\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5p7wtgMtk37",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# end page 142"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngPq4oc5TxqM",
        "colab_type": "text"
      },
      "source": [
        "**For Further Exploration**\n",
        "\n",
        "\n",
        "\n",
        "*   We've barely scratched the surface of what you should know about statistical inference. The books recommended at the end of Chapter 5 go into a lot more detail.\n",
        "*   Coursera offers a [Data Analysis and Statistical](https://www.coursera.org/specializations/statistics) Inference course that covers many of these topics.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9aAPYu2ttKB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}